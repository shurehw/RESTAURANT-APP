{
  "permissions": {
    "allow": [
      "Bash(npm install)",
      "Bash(supabase:*)",
      "Bash(npm install:*)",
      "Bash(docker:*)",
      "Bash(copy .env.example .env.local)",
      "Bash(npm run dev:*)",
      "Bash(del middleware.ts)",
      "Bash(npx shadcn@latest add:*)",
      "Read(//c/Users/JacobShure/Downloads/**)",
      "Bash(copy:*)",
      "Bash(ls:*)",
      "Bash(move apppage.tsx \"app\\(dashboard)\\page.tsx\")",
      "Bash(find:*)",
      "Bash(cat:*)",
      "Bash(psql:*)",
      "Bash(npx supabase db reset:*)",
      "Bash(del \"supabase\\migrations\\006_pricing_and_pos.sql\")",
      "Bash(del \"c:\\Users\\JacobShure\\RESTAURANT APP\\app\\budget\\page.tsx\")",
      "Bash(npx tsx:*)",
      "Bash(curl:*)",
      "Bash(move:*)",
      "Bash(unzip:*)",
      "Bash(npx supabase db diff:*)",
      "Bash(start http://localhost:3000/admin/customers)",
      "Bash(grep:*)",
      "Bash(npx supabase db execute:*)",
      "Bash(del \"app\\(dashboard)\\admin\\customers\" /s /q)",
      "Bash(del \"app\\(dashboard)\\admin\\venues\" /s /q)",
      "Bash(python:*)",
      "Bash(pip install:*)",
      "Bash(git remote add:*)",
      "Bash(git add:*)",
      "Bash(findstr:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nInitial commit: OpsOS Restaurant Intelligence Platform\n\nComplete MVP implementation with Intelligence Layer integration:\n- Auto-receiving and perpetual inventory system\n- Recipeâ†’Inventoryâ†’COGS integration with real-time processing\n- Labor forecasting and efficiency tracking\n- Real-time P&L with daily performance metrics\n- Exception-first workflow with automated alerts\n- Multi-tenant architecture with RLS policies\n- OpsOS visual identity (industrial, ledger-like UI)\n- IBM Plex Sans typography, ledger gold accents\n- Sharp 4px corners, 2px dot grid texture\n- Complete database migrations (001-043)\n- Python ML services for demand forecasting\n- POS integration (Square, Toast, R365)\n- Team messaging and time clock systems\n\nðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git push:*)",
      "Bash(gh repo create:*)",
      "Bash(git remote set-url:*)",
      "Bash(code .)",
      "Bash(gh auth:*)",
      "Bash(gh repo set-default:*)",
      "Bash(gh api:*)",
      "Bash(npm audit:*)",
      "Bash(git commit:*)",
      "Bash(npm run build:*)",
      "Bash(tee:*)",
      "Bash(git log:*)",
      "Bash(npx vercel:*)",
      "Bash(bash:*)",
      "Bash(npx supabase:*)",
      "Read(//c/Users/JacobShure/JBS life/**)",
      "Bash(git checkout:*)",
      "Bash(git pull:*)",
      "Bash(node:*)",
      "Bash(start http://localhost:3000)",
      "Bash(netstat:*)",
      "Bash(start http://localhost:3002)",
      "Bash(dir:*)",
      "Bash(start http://localhost:3002/login)",
      "Bash(taskkill:*)",
      "Bash(npx kill-port:*)",
      "Bash(start http://localhost:3001)",
      "Bash(echo $DATABASE_URL)",
      "Bash(npx tsc:*)",
      "Bash(start http://localhost:3001/proforma)",
      "Bash(del \".next\\dev\\lock\")",
      "Bash(rm:*)",
      "Bash(start docker)",
      "Bash(start:*)",
      "Bash(timeout:*)",
      "Bash(if exist .nextcache rd /s /q .nextcache)",
      "Bash(Get-Content \"dev-output.log\" -Tail 200)",
      "Bash(Select-String -Pattern \"Error|error|constraint|PATCH\" -Context 2)",
      "Bash(if exist \".next\\dev\\lock\" del \".next\\dev\\lock\")",
      "Bash(pkill:*)",
      "Bash(echo:*)",
      "Bash(Get-Process -Name node -ErrorAction SilentlyContinue)",
      "Bash(Select-Object Id, ProcessName)",
      "Bash(tasklist)",
      "Read(//c/**)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/check-venues.ts:*)",
      "Bash(export:*)",
      "Bash(awk:*)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/fix-gl-suggestion.ts:*)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/add-payment-terms.ts:*)",
      "Bash(set -a)",
      "Bash(source .env.local)",
      "Bash(set +a)",
      "Bash(Get-Content dev-output.log -Tail 100)",
      "Bash(Select-String -Pattern \"error|category|item\" -Context 1)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/backfill-proforma-defaults.ts:*)",
      "Bash(git reset:*)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/check-latest-invoice.ts:*)",
      "Bash(npm exec:*)",
      "Bash(npx dotenv -e .env.local -- npx tsx scripts/backfill-subcategories.ts:*)",
      "Bash(npx:*)",
      "Bash(Get-Content dev-output.log -Tail 50)",
      "Bash(Select-String -Pattern \"Pack configs|error|Error\" -Context 2)",
      "Bash(. .env.local)",
      "Bash(Select-String -Pattern \"invoice|upload|unauthorized|401|403\" -Context 3)",
      "Bash(node_modules/.bin/tsx:*)",
      "Bash(chmod:*)",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\5315 Bar Consumables\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\5320 Wine Cost\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(INVOICE_DIR='C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\5320 Wine Cost' bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\5335 NA Bev Cost\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Bev\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(Get-Content .env.local)",
      "Bash(Select-String \"NEXT_PUBLIC_SUPABASE_URL\")",
      "Bash(Select-String -Pattern \"GL|dropdown|select\" -Context 2)",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(where:*)",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food\" OUTPUT_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food Split\" npx tsx scripts/split-large-pdfs.ts)",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food Split\" bash scripts/run-bulk-import.sh \"Delilah Dallas\")",
      "Bash(INVOICE_DIR='C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food' node_modules/.bin/tsx scripts/bulk-import-invoices.ts \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food\" npx dotenv -e .env.local -- npx tsx scripts/bulk-import-invoices.ts \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food\" node_modules/.bin/tsx scripts/bulk-import-invoices.ts \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food - Small\" node_modules/.bin/tsx scripts/import-small-chunks.ts \"Delilah Dallas\")",
      "Bash(Select-String -Pattern \"invoice-lines|map|404|POST\" -Context 2)",
      "Bash(if [ -f \".next/dev/lock\" ])",
      "Bash(then rm \".next/dev/lock\")",
      "Bash(else echo \"No lock file\")",
      "Bash(fi)",
      "Bash(INVOICE_DIR=\"C:\\Users\\JacobShure\\OneDrive - Hwood Group\\Finance - Delilah Dallas Finance - Temp Invoice Scans\\Multiple Food - Split\" node_modules/.bin/tsx scripts/import-small-chunks.ts \"Delilah Dallas\")",
      "Bash(INVOICE_DIR=\"/c/Users/JacobShure/OneDrive - Hwood Group/Finance - Delilah Dallas Finance - Temp Invoice Scans/Multiple Food Split\" node_modules/.bin/tsx scripts/import-small-chunks.ts \"Delilah Dallas\")",
      "Bash(tail:*)",
      "Bash(Select-String -Pattern \"invoice|upload|fetch|error|Error|POST\" -Context 2)",
      "Bash(powershell:*)",
      "Bash(INVOICE_DIR=\"/c/Users/JacobShure/OneDrive - Hwood Group/Finance - Delilah Dallas Finance - Temp Invoice Scans/Multiple Food Split\" OUTPUT_DIR=\"/c/Users/JacobShure/OneDrive - Hwood Group/Finance - Delilah Dallas Finance - Temp Invoice Scans/Multiple Food Pages\" node_modules/.bin/tsx scripts/split-large-pdfs.ts)",
      "Bash(Select-String -Pattern \"InvoiceLineMapper|InvoicePDFViewer|error|Error\" -Context 2)",
      "Bash(code:*)",
      "Bash(ping:*)",
      "Bash(npx next dev:*)",
      "Bash(node node_modules/next/dist/bin/next dev:*)",
      "Bash(git config:*)",
      "Bash(node_modules/.bin/tsc:*)",
      "Bash(node scripts/list-tipsee.js:*)",
      "Bash(SUPABASE_ACCESS_TOKEN=SUPABASE_ACCESS_TOKEN_REDACTED npx supabase secrets set TIPSEE_DB_HOST=TIPSEE_HOST_REDACTED TIPSEE_DB_USER=TIPSEE_USERNAME_REDACTED TIPSEE_DB_PASSWORD=TIPSEE_PASSWORD_REDACTED TIPSEE_DB_PORT=5432 TIPSEE_DB_NAME=postgres)",
      "Bash(SUPABASE_ACCESS_TOKEN=SUPABASE_ACCESS_TOKEN_REDACTED npx supabase:*)",
      "Bash(python scripts/list-tipsee.py:*)",
      "Bash(TIPSEE_DB_HOST=TIPSEE_HOST_REDACTED TIPSEE_DB_USER=TIPSEE_USERNAME_REDACTED TIPSEE_DB_PASSWORD=TIPSEE_PASSWORD_REDACTED TIPSEE_DB_NAME=postgres python scripts/list-tipsee.py)",
      "Bash(pip show:*)",
      "Bash(PGPASSWORD=TIPSEE_PASSWORD_REDACTED psql:*)",
      "Bash(TIPSEE_DB_HOST=TIPSEE_HOST_REDACTED TIPSEE_DB_USER=TIPSEE_USERNAME_REDACTED TIPSEE_DB_PASSWORD=TIPSEE_PASSWORD_REDACTED TIPSEE_DB_NAME=postgres TIPSEE_DB_PORT=5432 python:*)",
      "Bash(git mv:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix nightly comps to capture item-level data and add tabbed view\n\n- Update TipSee queries to capture comps from both check-level and item-level\n- Add tabbed Comps & Discounts section with \"By Reason\" and \"All Comps\" views\n- Show overall comp % of net sales and percentage breakdown by reason\n- Remove separate Detailed Comp Report section \\(now integrated into tabs\\)\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(head:*)",
      "Bash(npm run lint:*)",
      "Bash(npx next lint)",
      "Bash(powershell -Command:*)",
      "Bash(npx supabase db push:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix NaN% in comps by converting PostgreSQL numeric strings to numbers\n\nPostgreSQL returns SUM\\(\\) and numeric types as strings in node-postgres.\nThe cleanRow function only handled bigint conversion, causing string\nconcatenation instead of addition when calculating comp percentages.\n\nCo-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(node -e:*)",
      "Bash(npx ts-node:*)",
      "Bash(more:*)",
      "Bash(node scripts/run-backfill.mjs:*)",
      "Bash(node scripts/direct-backfill.mjs:*)",
      "Bash(vercel --version:*)",
      "WebFetch(domain:opsos-restaurant-djwn0436j-shureprint.vercel.app)",
      "WebFetch(domain:opsos-restaurant-7m5ifljrl-shureprint.vercel.app)",
      "Bash(python3:*)",
      "Bash(xargs:*)",
      "Bash(node scripts/query-tipsee-labor.mjs:*)",
      "Bash(npx next dev)",
      "Bash(node query.js:*)",
      "Bash(node scripts/check-accuracy.mjs:*)",
      "Bash(npx next lint:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFetch labor data from TipSee punches table for nightly report\n\nReplaces empty Supabase materialized view \\(labor_efficiency_daily\\) with\ndirect queries to TipSee punches table which has 189K+ rows of actual\nclock-in/out data with hourly wages and pre-calculated hours.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git status:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nSync TipSee labor data into labor_day_facts table\n\n- New migration: labor_day_facts with computed labor_pct, splh, covers_per_hr\n- ETL edge function: extracts punches data alongside sales sync\n- Backfill script: includes labor extraction from TipSee punches table\n- Facts API: reads from labor_day_facts with live TipSee fallback\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nAdd forecast infrastructure: pacing, overrides, auto-decay, and labor facts\n\n- Migration 179: Override logging with reason codes and layer snapshots\n- Migration 180: Pacing baselines and compute_pacing_multiplier function\n- Migration 181: Bias auto-decay \\(10%/week, holidays manual, 12-cycle cap\\)\n- Migration 182: Cron jobs for weekly decay, daily outcome recording, pacing refresh\n- Migration 183: 4-layer forecast view \\(base + day_type + holiday\\) * pacing\n- Migration 184: Labor day facts table for TipSee punch data\n- Override API: POST/GET /api/forecast/override with auth and layer snapshots\n- Override UI: Dialog with layer breakdown, reason codes, delta badge\n- Forecasts page now reads forecasts_with_bias \\(bias-corrected values\\)\n- ForecastTable shows layer badges \\(DT, Holiday, Pacing\\) and override state\n- Accuracy scripts for production monitoring \\(zero-dep, raw fetch\\)\n- Venue class split: Nice Guy=high_end_social, Delilahs=supper_club\n- Offset tuning: Keys Sat +27->+15, Bird Streets Sat +11->+5, Sun +4->0\n- Current MAPE: 28.3% raw -> 25.3% corrected \\(11% relative improvement\\)\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(node run-backfill.mjs:*)",
      "Bash(set:*)",
      "Bash(node test-labor.js:*)",
      "Bash(/c/temp/check-foh-boh.js << 'SCRIPT'\nconst path = require\\('path'\\);\nconst { Pool } = require\\(path.join\\(__dirname, 'node_modules', 'pg'\\)\\);\n\nconst pool = new Pool\\({\n  host: 'TIPSEE_HOST_REDACTED',\n  user: 'TIPSEE_USERNAME_REDACTED',\n  port: 5432,\n  database: 'postgres',\n  password: 'TIPSEE_PASSWORD_REDACTED',\n  ssl: { rejectUnauthorized: false },\n  connectionTimeoutMillis: 15000,\n}\\);\n\nasync function main\\(\\) {\n  const client = await pool.connect\\(\\);\n  try {\n    // 1. Get column names\n    console.log\\('=== COLUMNS IN tipsee_7shifts_punches ==='\\);\n    const colRes = await client.query\\(`\n      SELECT column_name, data_type\n      FROM information_schema.columns\n      WHERE table_name = 'tipsee_7shifts_punches'\n      ORDER BY ordinal_position\n    `\\);\n    for \\(const row of colRes.rows\\) {\n      console.log\\('  ' + row.column_name + ' \\(' + row.data_type + '\\)'\\);\n    }\n\n    // Identify role/department/position columns\n    const rolePattern = /role|department|dept|position|title|job|type|category/i;\n    const roleCols = colRes.rows\n      .filter\\(r => rolePattern.test\\(r.column_name\\)\\)\n      .map\\(r => r.column_name\\);\n\n    console.log\\(''\\);\n    console.log\\('=== ROLE/DEPARTMENT/POSITION COLUMNS DETECTED ==='\\);\n    console.log\\('  ' + \\(roleCols.length > 0 ? roleCols.join\\(', '\\) : '\\(none found\\)'\\)\\);\n\n    // 2. Get distinct values for each role/dept column\n    if \\(roleCols.length > 0\\) {\n      for \\(const col of roleCols\\) {\n        console.log\\(''\\);\n        console.log\\('=== DISTINCT VALUES FOR \"' + col + '\" ==='\\);\n        const distinctRes = await client.query\\(\n          'SELECT DISTINCT \"' + col + '\", COUNT\\(*\\) as cnt FROM tipsee_7shifts_punches GROUP BY \"' + col + '\" ORDER BY cnt DESC LIMIT 50'\n        \\);\n        for \\(const row of distinctRes.rows\\) {\n          console.log\\('  ' + row[col] + ' \\(' + row.cnt + ' rows\\)'\\);\n        }\n      }\n    }\n\n    // 3. Sample a few rows to see all data\n    console.log\\(''\\);\n    console.log\\('=== SAMPLE ROW \\(all columns\\) ==='\\);\n    const sampleRes = await client.query\\('SELECT * FROM tipsee_7shifts_punches LIMIT 1'\\);\n    if \\(sampleRes.rows.length > 0\\) {\n      for \\(const [k, v] of Object.entries\\(sampleRes.rows[0]\\)\\) {\n        console.log\\('  ' + k + ': ' + v\\);\n      }\n    }\n\n    // 4. For specific date & location, breakdown by role/dept columns\n    const locationUuid = 'aeb1790a-1ce9-4d6c-b1bc-7ef618294dc4';\n    const targetDate = '2026-02-04';\n\n    console.log\\(''\\);\n    console.log\\('=== BREAKDOWN FOR location=' + locationUuid + ', date=' + targetDate + ' ==='\\);\n\n    if \\(roleCols.length > 0\\) {\n      for \\(const col of roleCols\\) {\n        console.log\\(''\\);\n        console.log\\('--- By \"' + col + '\" ---'\\);\n        const breakdownRes = await client.query\\(\n          'SELECT \"' + col + '\", COUNT\\(*\\) as punch_count, ROUND\\(SUM\\(COALESCE\\(total_hours, 0\\)\\)::numeric, 2\\) as total_hours, ROUND\\(SUM\\(COALESCE\\(total_cost, 0\\)\\)::numeric, 2\\) as total_cost FROM tipsee_7shifts_punches WHERE location_uuid = $1 AND date = $2 GROUP BY \"' + col + '\" ORDER BY total_cost DESC',\n          [locationUuid, targetDate]\n        \\);\n        if \\(breakdownRes.rows.length === 0\\) {\n          console.log\\('  \\(no rows found for this date/location\\)'\\);\n          const dateCheck = await client.query\\(\n            'SELECT DISTINCT date FROM tipsee_7shifts_punches WHERE location_uuid = $1 ORDER BY date DESC LIMIT 5',\n            [locationUuid]\n          \\);\n          console.log\\('  Recent dates for this location:', dateCheck.rows.map\\(r => r.date\\)\\);\n        } else {\n          for \\(const row of breakdownRes.rows\\) {\n            console.log\\('  ' + row[col] + ': ' + row.punch_count + ' punches, ' + row.total_hours + ' hrs,  + row.total_cost\\);\n          }\n        }\n      }\n    } else {\n      console.log\\('No role/department columns found. Showing totals only:'\\);\n      const totalRes = await client.query\\(\n        'SELECT COUNT\\(*\\) as punch_count, ROUND\\(SUM\\(COALESCE\\(total_hours, 0\\)\\)::numeric, 2\\) as total_hours, ROUND\\(SUM\\(COALESCE\\(total_cost, 0\\)\\)::numeric, 2\\) as total_cost FROM tipsee_7shifts_punches WHERE location_uuid = $1 AND date = $2',\n        [locationUuid, targetDate]\n      \\);\n      console.log\\('  ', totalRes.rows[0]\\);\n    }\n\n  } finally {\n    client.release\\(\\);\n    await pool.end\\(\\);\n  }\n}\n\nmain\\(\\).catch\\(err => {\n  console.error\\('ERROR:', err.message\\);\n  pool.end\\(\\);\n  process.exit\\(1\\);\n}\\);\nSCRIPT)",
      "Bash(/c/temp/check-foh-boh.js << 'SCRIPT'\nconst path = require\\('path'\\);\nconst { Pool } = require\\(path.join\\(__dirname, 'node_modules', 'pg'\\)\\);\n\nconst pool = new Pool\\({\n  host: 'TIPSEE_HOST_REDACTED',\n  user: 'TIPSEE_USERNAME_REDACTED',\n  port: 5432,\n  database: 'postgres',\n  password: 'TIPSEE_PASSWORD_REDACTED',\n  ssl: { rejectUnauthorized: false },\n  connectionTimeoutMillis: 15000,\n}\\);\n\nasync function main\\(\\) {\n  const client = await pool.connect\\(\\);\n  try {\n    // 1. Check for 7shifts role/department lookup tables\n    console.log\\('=== LOOKING FOR 7SHIFTS ROLE/DEPARTMENT LOOKUP TABLES ==='\\);\n    const tablesRes = await client.query\\(`\n      SELECT table_name FROM information_schema.tables\n      WHERE table_schema = 'public'\n        AND \\(table_name LIKE '%7shift%' OR table_name LIKE '%role%' OR table_name LIKE '%department%'\\)\n      ORDER BY table_name\n    `\\);\n    for \\(const row of tablesRes.rows\\) {\n      console.log\\('  ' + row.table_name\\);\n    }\n\n    // 2. Check if there's a roles table with names\n    for \\(const tbl of tablesRes.rows\\) {\n      const tn = tbl.table_name;\n      if \\(tn.includes\\('role'\\) || tn.includes\\('department'\\)\\) {\n        console.log\\(''\\);\n        console.log\\('=== COLUMNS IN ' + tn + ' ==='\\);\n        const colRes = await client.query\\(\n          \"SELECT column_name, data_type FROM information_schema.columns WHERE table_name = $1 ORDER BY ordinal_position\",\n          [tn]\n        \\);\n        for \\(const row of colRes.rows\\) {\n          console.log\\('  ' + row.column_name + ' \\(' + row.data_type + '\\)'\\);\n        }\n        // Show sample\n        console.log\\('--- Sample from ' + tn + ' ---'\\);\n        const sampleRes = await client.query\\('SELECT * FROM \"' + tn + '\" LIMIT 10'\\);\n        for \\(const row of sampleRes.rows\\) {\n          console.log\\('  ' + JSON.stringify\\(row\\)\\);\n        }\n      }\n    }\n\n    // 3. Now check the specific date/location with proper columns\n    const locationUuid = 'aeb1790a-1ce9-4d6c-b1bc-7ef618294dc4';\n    const targetDate = '2026-02-04';\n\n    console.log\\(''\\);\n    console.log\\('=== CHECKING AVAILABLE DATES FOR LOCATION ==='\\);\n    const dateCheck = await client.query\\(\n      \"SELECT DISTINCT trading_day FROM tipsee_7shifts_punches WHERE location_uuid = $1 ORDER BY trading_day DESC LIMIT 10\",\n      [locationUuid]\n    \\);\n    console.log\\('Recent trading_days:', dateCheck.rows.map\\(r => r.trading_day\\)\\);\n\n    // Calculate labor cost = hourly_wage \\(in cents\\) * total_hours\n    console.log\\(''\\);\n    console.log\\('=== BREAKDOWN BY role_id FOR ' + targetDate + ' ==='\\);\n    const roleBreakdown = await client.query\\(`\n      SELECT role_id,\n             COUNT\\(*\\) as punch_count,\n             ROUND\\(SUM\\(COALESCE\\(total_hours, 0\\)\\)::numeric, 2\\) as total_hours,\n             ROUND\\(SUM\\(COALESCE\\(hourly_wage, 0\\) * COALESCE\\(total_hours, 0\\) / 100\\)::numeric, 2\\) as labor_cost\n      FROM tipsee_7shifts_punches\n      WHERE location_uuid = $1 AND trading_day = $2\n      GROUP BY role_id\n      ORDER BY labor_cost DESC\n    `, [locationUuid, targetDate]\\);\n    if \\(roleBreakdown.rows.length === 0\\) {\n      console.log\\('  \\(no data for this date\\)'\\);\n    } else {\n      for \\(const row of roleBreakdown.rows\\) {\n        console.log\\('  role_id=' + row.role_id + ': ' + row.punch_count + ' punches, ' + row.total_hours + ' hrs,  + row.labor_cost\\);\n      }\n    }\n\n    console.log\\(''\\);\n    console.log\\('=== BREAKDOWN BY department_id FOR ' + targetDate + ' ==='\\);\n    const deptBreakdown = await client.query\\(`\n      SELECT department_id,\n             COUNT\\(*\\) as punch_count,\n             ROUND\\(SUM\\(COALESCE\\(total_hours, 0\\)\\)::numeric, 2\\) as total_hours,\n             ROUND\\(SUM\\(COALESCE\\(hourly_wage, 0\\) * COALESCE\\(total_hours, 0\\) / 100\\)::numeric, 2\\) as labor_cost\n      FROM tipsee_7shifts_punches\n      WHERE location_uuid = $1 AND trading_day = $2\n      GROUP BY department_id\n      ORDER BY labor_cost DESC\n    `, [locationUuid, targetDate]\\);\n    if \\(deptBreakdown.rows.length === 0\\) {\n      console.log\\('  \\(no data for this date\\)'\\);\n    } else {\n      for \\(const row of deptBreakdown.rows\\) {\n        console.log\\('  dept_id=' + row.department_id + ': ' + row.punch_count + ' punches, ' + row.total_hours + ' hrs,  + row.labor_cost\\);\n      }\n    }\n\n    // 4. If there are role/dept lookup tables, join them\n    // Check for tipsee_7shifts_roles or similar\n    const rolesTableCheck = await client.query\\(`\n      SELECT table_name FROM information_schema.tables\n      WHERE table_schema = 'public'\n        AND table_name LIKE '%7shifts%'\n      ORDER BY table_name\n    `\\);\n    console.log\\(''\\);\n    console.log\\('=== ALL 7SHIFTS TABLES ==='\\);\n    for \\(const row of rolesTableCheck.rows\\) {\n      console.log\\('  ' + row.table_name\\);\n    }\n\n  } finally {\n    client.release\\(\\);\n    await pool.end\\(\\);\n  }\n}\n\nmain\\(\\).catch\\(err => {\n  console.error\\('ERROR:', err.message\\);\n  pool.end\\(\\);\n  process.exit\\(1\\);\n}\\);\nSCRIPT)",
      "Bash(/c/temp/check-foh-boh.js << 'ENDOFSCRIPT'\nconst path = require\\('path'\\);\nconst { Pool } = require\\(path.join\\(__dirname, 'node_modules', 'pg'\\)\\);\n\nconst pool = new Pool\\({\n  host: 'TIPSEE_HOST_REDACTED',\n  user: 'TIPSEE_USERNAME_REDACTED',\n  port: 5432,\n  database: 'postgres',\n  password: 'TIPSEE_PASSWORD_REDACTED',\n  ssl: { rejectUnauthorized: false },\n  connectionTimeoutMillis: 15000,\n}\\);\n\nasync function main\\(\\) {\n  const client = await pool.connect\\(\\);\n  try {\n    const locationUuid = 'aeb1790a-1ce9-4d6c-b1bc-7ef618294dc4';\n    const targetDate = '2026-02-04';\n\n    // 1. Check how dates work\n    console.log\\('=== DATE FIELD CHECK FOR THIS LOCATION ==='\\);\n    const dateFieldCheck = await client.query\\(\n      \"SELECT COUNT\\(*\\) as total_rows, COUNT\\(trading_day\\) as has_trading_day, COUNT\\(clocked_in\\) as has_clocked_in, MIN\\(clocked_in::date\\) as earliest, MAX\\(clocked_in::date\\) as latest FROM tipsee_7shifts_punches WHERE location_uuid = $1\",\n      [locationUuid]\n    \\);\n    console.log\\('  ' + JSON.stringify\\(dateFieldCheck.rows[0]\\)\\);\n\n    // 2. Recent dates\n    console.log\\('\\\\n=== RECENT DATES \\(via clocked_in\\) ==='\\);\n    const recentDates = await client.query\\(\n      \"SELECT DISTINCT clocked_in::date as d, COUNT\\(*\\) as cnt FROM tipsee_7shifts_punches WHERE location_uuid = $1 GROUP BY clocked_in::date ORDER BY d DESC LIMIT 10\",\n      [locationUuid]\n    \\);\n    for \\(const row of recentDates.rows\\) {\n      console.log\\('  ' + row.d.toISOString\\(\\).slice\\(0,10\\) + ': ' + row.cnt + ' punches'\\);\n    }\n\n    // 3. Departments for location\n    console.log\\('\\\\n=== DEPARTMENTS FOR THE NICE GUY ==='\\);\n    const deptRes = await client.query\\(\n      \"SELECT DISTINCT id, name FROM departments WHERE location_uuid = $1 ORDER BY name\",\n      [locationUuid]\n    \\);\n    for \\(const row of deptRes.rows\\) {\n      console.log\\('  dept_id=' + row.id + ' -> ' + row.name\\);\n    }\n\n    // 4. Roles for location\n    console.log\\('\\\\n=== ROLES FOR THE NICE GUY ==='\\);\n    const roleRes = await client.query\\(\n      \"SELECT r.id, r.role_name, r.department_id, d.name as dept_name FROM roles r LEFT JOIN departments d ON d.id = r.department_id WHERE r.location_uuid = $1 AND \\(r.is_deleted = false OR r.is_deleted IS NULL\\) ORDER BY d.name, r.role_name\",\n      [locationUuid]\n    \\);\n    for \\(const row of roleRes.rows\\) {\n      console.log\\('  [' + \\(row.dept_name || '?'\\) + '] role_id=' + row.id + ' -> ' + row.role_name\\);\n    }\n\n    // 5. Total hours check\n    console.log\\('\\\\n=== TOTAL_HOURS FIELD CHECK ==='\\);\n    const hoursCheck = await client.query\\(\n      \"SELECT COUNT\\(*\\) as total, COUNT\\(total_hours\\) as has_hours, COUNT\\(*\\) - COUNT\\(total_hours\\) as missing FROM tipsee_7shifts_punches WHERE location_uuid = $1 AND clocked_in::date = $2::date\",\n      [locationUuid, targetDate]\n    \\);\n    console.log\\('  ' + JSON.stringify\\(hoursCheck.rows[0]\\)\\);\n\n    // 6. Department breakdown - computed hours\n    console.log\\('\\\\n=== LABOR BY DEPARTMENT - ' + targetDate + ' ==='\\);\n    const deptBreakdown = await client.query\\(\n      \"SELECT d.name as dept, COUNT\\(*\\) as punches, ROUND\\(SUM\\(EXTRACT\\(EPOCH FROM \\(p.clocked_out - p.clocked_in\\)\\) / 3600\\)::numeric, 2\\) as hours, ROUND\\(SUM\\(COALESCE\\(p.hourly_wage, 0\\) * EXTRACT\\(EPOCH FROM \\(p.clocked_out - p.clocked_in\\)\\) / 3600 / 100\\)::numeric, 2\\) as cost FROM tipsee_7shifts_punches p LEFT JOIN departments d ON d.id = p.department_id WHERE p.location_uuid = $1 AND p.clocked_in::date = $2::date AND p.clocked_out IS NOT NULL GROUP BY d.name ORDER BY cost DESC\",\n      [locationUuid, targetDate]\n    \\);\n    if \\(deptBreakdown.rows.length === 0\\) {\n      console.log\\('  \\(no data\\)'\\);\n    } else {\n      let totalH = 0, totalC = 0;\n      for \\(const row of deptBreakdown.rows\\) {\n        console.log\\('  ' + \\(row.dept || 'UNKNOWN'\\) + ': ' + row.punches + ' punches, ' + row.hours + ' hrs,  + row.cost\\);\n        totalH += parseFloat\\(row.hours || 0\\);\n        totalC += parseFloat\\(row.cost || 0\\);\n      }\n      console.log\\('  ---'\\);\n      console.log\\('  TOTAL: ' + totalH.toFixed\\(2\\) + ' hrs,  + totalC.toFixed\\(2\\)\\);\n    }\n\n    // 7. Role breakdown\n    console.log\\('\\\\n=== LABOR BY ROLE - ' + targetDate + ' ==='\\);\n    const roleBreakdown = await client.query\\(\n      \"SELECT r.role_name, d.name as dept, COUNT\\(*\\) as punches, ROUND\\(SUM\\(EXTRACT\\(EPOCH FROM \\(p.clocked_out - p.clocked_in\\)\\) / 3600\\)::numeric, 2\\) as hours, ROUND\\(SUM\\(COALESCE\\(p.hourly_wage, 0\\) * EXTRACT\\(EPOCH FROM \\(p.clocked_out - p.clocked_in\\)\\) / 3600 / 100\\)::numeric, 2\\) as cost FROM tipsee_7shifts_punches p LEFT JOIN roles r ON r.id = p.role_id LEFT JOIN departments d ON d.id = p.department_id WHERE p.location_uuid = $1 AND p.clocked_in::date = $2::date AND p.clocked_out IS NOT NULL GROUP BY r.role_name, d.name ORDER BY d.name, cost DESC\",\n      [locationUuid, targetDate]\n    \\);\n    if \\(roleBreakdown.rows.length === 0\\) {\n      console.log\\('  \\(no data\\)'\\);\n    } else {\n      for \\(const row of roleBreakdown.rows\\) {\n        console.log\\('  [' + \\(row.dept || '?'\\) + '] ' + \\(row.role_name || 'UNKNOWN'\\) + ': ' + row.punches + ' punches, ' + row.hours + ' hrs,  + row.cost\\);\n      }\n    }\n\n    // 8. All department names\n    console.log\\('\\\\n=== ALL DEPARTMENT NAMES \\(ALL LOCATIONS\\) ==='\\);\n    const allDepts = await client.query\\(\"SELECT DISTINCT name FROM departments ORDER BY name\"\\);\n    for \\(const row of allDepts.rows\\) {\n      console.log\\('  ' + row.name\\);\n    }\n\n  } finally {\n    client.release\\(\\);\n    await pool.end\\(\\);\n  }\n}\n\nmain\\(\\).catch\\(err => {\n  console.error\\('ERROR:', err.message\\);\n  pool.end\\(\\);\n  process.exit\\(1\\);\n}\\);\nENDOFSCRIPT)",
      "Bash(nvm list:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix PTD using week boundaries instead of fiscal period boundaries\n\nConfigure 4-4-5 fiscal calendar with FY start 2025-12-29 so PTD\naggregates from the correct period start \\(e.g. Jan 26 for Period 2\\).\nAlso fix the ''standard'' calendar fallback to use month boundaries\ninstead of week boundaries.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix FOH/BOH split to show labor % of sales, not share of total labor\n\nBar fills 100% \\(proportional share\\), labels show each dept as % of net sales.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "WebFetch(domain:tenzo.zendesk.com)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:www.widewail.com)",
      "WebFetch(domain:developer.widewail.com)",
      "Bash(node scripts/list-tipsee-tables.mjs:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nAdd venue health rating system with review signals and iterative fixes\n\nComposite health score \\(0-100\\) from weighted signals \\(reviews, sales, leakage\\)\nwith GREEN/YELLOW/ORANGE/RED status and automated trigger actions. Includes\nreview sync ETL from TipSee/Widewail, venue-class weight fallback, format\\(\\)\nspecifier fixes, and graceful handling of missing forecast table.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(gh api repos/shurehw/RESTAURANT-APP/deployments --jq '.[] | select\\(.environment == \"\"Production\"\"\\) | .id')",
      "WebFetch(domain:opsos-restaurant-onrzyojc5-shureprint.vercel.app)",
      "Bash(if not exist \"%TEMP%\\\\review-backfill\" mkdir \"%TEMP%\\\\review-backfill\")",
      "Bash(wc:*)",
      "Bash(test -f:*)",
      "Bash(test:*)",
      "Bash(npx next build:*)",
      "Bash(git clone:*)",
      "Bash(supabase db push:*)",
      "Bash(\"app/\\(dashboard\\)/admin/comp-settings/page.tsx\" << 'EOF'\nexport const dynamic = 'force-dynamic';\n\nimport { createClient } from '@/lib/supabase/server';\nimport { CompSettingsManager } from '@/components/admin/CompSettingsManager';\n\nexport default async function AdminCompSettingsPage\\(\\) {\n  const supabase = await createClient\\(\\);\n\n  // Get current user's organizations\n  const { data: { user } } = await supabase.auth.getUser\\(\\);\n  \n  const { data: orgs } = await supabase\n    .from\\('organization_users'\\)\n    .select\\(`\n      organization_id,\n      role,\n      organizations \\(\n        id,\n        name,\n        logo_url\n      \\)\n    `\\)\n    .eq\\('user_id', user?.id\\)\n    .eq\\('is_active', true\\);\n\n  const organizations = orgs?.map\\(o => o.organizations\\).filter\\(Boolean\\) || [];\n\n  return \\(\n    <div className=\"container max-w-7xl mx-auto py-8\">\n      <h1 className=\"page-header\">Comp Policy Settings</h1>\n      <p className=\"text-muted-foreground mb-8\">\n        Configure enforcement rules, thresholds, and approved comp reasons for each organization\n      </p>\n\n      <CompSettingsManager organizations={organizations as any[]} />\n    </div>\n  \\);\n}\nEOF)",
      "Bash(\"components/admin/CompSettingsForm.tsx\" <<'ENDFILE'\n'use client';\n\nimport { useState } from 'react';\n\nexport function CompSettingsForm\\({ settings, onSave, loading }: any\\) {\n  const [formData, setFormData] = useState\\({\n    high_value_comp_threshold: settings.high_value_comp_threshold || 200,\n    daily_comp_pct_warning: settings.daily_comp_pct_warning || 2,\n    daily_comp_pct_critical: settings.daily_comp_pct_critical || 3,\n    server_max_comp_amount: settings.server_max_comp_amount || 50,\n  }\\);\n\n  return \\(\n    <form onSubmit={\\(e\\) => { e.preventDefault\\(\\); onSave\\(formData\\); }} className=\"space-y-6\">\n      <div className=\"grid grid-cols-2 gap-4\">\n        <div>\n          <label className=\"block mb-2\">High Value Threshold \\($\\)</label>\n          <input\n            type=\"number\"\n            value={formData.high_value_comp_threshold}\n            onChange={\\(e\\) => setFormData\\({ ...formData, high_value_comp_threshold: +e.target.value }\\)}\n            className=\"w-full px-3 py-2 border rounded\"\n          />\n        </div>\n        <div>\n          <label className=\"block mb-2\">Server Max Amount \\($\\)</label>\n          <input\n            type=\"number\"\n            value={formData.server_max_comp_amount}\n            onChange={\\(e\\) => setFormData\\({ ...formData, server_max_comp_amount: +e.target.value }\\)}\n            className=\"w-full px-3 py-2 border rounded\"\n          />\n        </div>\n      </div>\n      <button type=\"submit\" disabled={loading} className=\"px-4 py-2 bg-blue-600 text-white rounded\">\n        {loading ? 'Saving...' : 'Save Settings'}\n      </button>\n    </form>\n  \\);\n}\nENDFILE)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nAdd tunable enforcement rails for comp policy management\n\nBuilt complete comp settings system with bounded calibration:\n- Settings â†’ Exception Detection â†’ AI Review â†’ Control Plane\n- Org-specific thresholds within fixed standards\n- Full admin UI with CRUD, version history, import/export\n- Logo upload for branded SOPs\n- Multi-format SOP generation \\(HTML, Markdown, JSON\\)\n\nCore principle: Rules are always on. Rails are fixed. \nCalibration is allowed. Escape is not.\n\nTechnical changes:\n- fetchCompExceptions\\(\\) accepts org settings parameter\n- reviewComps\\(\\) uses org settings for dynamic prompts\n- Complete database layer with P0-style versioning\n- RLS policies, audit logging, effective dating\n- Admin UI at /admin/comp-settings\n\nDocumentation:\n- Product North Star \\(enforcement principles\\)\n- Canonical Description \\(external positioning\\)\n- Investor Positioning \\(market defense\\)\n- Complete technical documentation\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git restore:*)",
      "Bash(git stash:*)",
      "Bash(vercel:*)",
      "Bash(npx vercel ls:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nDisable prefetching on sidebar navigation links\n\nISSUE: Sidebar links were prefetching all routes on hover/viewport\n- 20+ Link components without prefetch={false}\n- Each triggered RSC prefetch request\n- Exhausted browser connection pool \\(6 concurrent limit\\)\n- Blocked actual data requests\n\nFIX: Add prefetch={false} to NavLink component\n- Prevents automatic prefetching of all sidebar routes\n- Frees connection slots for critical data requests\n- Navigation still instant \\(client-side routing works normally\\)\n\nIMPACT:\n- Nightly report data loads immediately \\(not blocked\\)\n- No more 2-minute waits for data requests\n- Sidebar navigation still fast \\(just not pre-cached\\)\n\nCo-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(/c/Dev/RESTAURANT-APP/scripts/fix-venue-mappings.sql << 'EOF'\n-- Fix fake venue IDs in venue_tipsee_mapping\n-- Replace placeholder UUIDs with real venue IDs\n\n-- Get actual venue IDs and update mappings\nUPDATE venue_tipsee_mapping vtm\nSET venue_id = v.id\nFROM venues v\nWHERE vtm.tipsee_location_name ILIKE '%' || v.name || '%'\n  AND vtm.venue_id IN \\(\n    '11111111-1111-1111-1111-111111111111',\n    '22222222-2222-2222-2222-222222222222'\n  \\);\n\n-- Show updated mappings\nSELECT \n  vtm.venue_id,\n  v.name as venue_name,\n  vtm.tipsee_location_name,\n  vtm.tipsee_location_uuid\nFROM venue_tipsee_mapping vtm\nJOIN venues v ON v.id = vtm.venue_id\nWHERE vtm.is_active = true\nORDER BY v.name;\nEOF)",
      "Bash(openssl rand:*)",
      "Bash(npx vercel env add:*)",
      "Bash(1 << 'EOF'\nCRON_SECRET_REDACTED\nEOF)",
      "WebFetch(domain:docs.restaurant365.com)",
      "WebFetch(domain:help.restaurant365.net)",
      "Bash(npx next build)",
      "Bash(while ! grep -q \"Update complete\" \"C:\\\\Users\\\\JACOBS~1\\\\AppData\\\\Local\\\\Temp\\\\claude\\\\c--Dev-RESTAURANT-APP\\\\tasks\\\\b353f57.output\")",
      "Bash(do sleep 5)",
      "Bash(done)",
      "Bash(npx vercel logs:*)",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix build: null safety for factsSummary, comp-signals types, chatbot error surfacing\n\n- Add optional chaining for factsSummary?.variance?. in nightly report page\n- Fix comp-signals route: correct CompException property names, use SignalInput type\n- Surface actual error messages in chatbot tool executor instead of generic fallback\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git commit -m \"$\\(cat <<''EOF''\nFix chatbot: cast location_uuid params to uuid[] instead of text[]\n\nThe TipSee location_uuid column is UUID type. Queries were casting\nparams as text[], causing \"operator does not exist: uuid = text\" errors\non every chatbot tool call.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(comm:*)",
      "Read(//c/tmp/**)",
      "Bash(node scripts/run-migration-223.mjs:*)",
      "WebFetch(domain:developer.ui.com)",
      "WebFetch(domain:opsos-restaurant-app.vercel.app)",
      "Bash(npx --yes sharp-cli:*)",
      "Bash(npx sharp-cli:*)",
      "Bash(dir \"%APPDATA%\\\\supabase\"\" 2>nul && type \"%APPDATA%supabaseaccess-token\" 2>nul | findstr /r \".\" | head -1 || echo \"Not at APPDATA \")",
      "Bash(dir /s /b \"C:\\\\Users\\\\JACOBS~1\\\\*access-token*\")",
      "Bash(for ver in 030 045 1000 1001 1002 100 103 107 110 119 124 136 143 148 161 208 209 210 211 212 220 222 999)",
      "Bash(do npx supabase migration repair --status applied $ver)",
      "Bash(npx psql:*)",
      "Bash(for v in 030 045 1000 1001 1002 100 103 107 110 119 124 136 143 148 161)",
      "Bash(do npx supabase migration repair --status applied $v)",
      "Bash(npm config:*)",
      "Bash(npx vercel env:*)",
      "WebFetch(domain:help.ui.com)",
      "Bash(node scripts/manual-poll.js:*)",
      "Bash(del \"c:\\\\Dev\\\\RESTAURANT-APP\\\\.next\\\\lock\")",
      "Bash(git stash pop:*)",
      "Bash(npm ls:*)",
      "Bash(npx playwright:*)",
      "Bash(npm run:*)",
      "Bash(del \"C:\\\\Dev\\\\RESTAURANT-APP\\\\.next\\\\lock\")",
      "Bash(start \"\" \"c:\\\\Dev\\\\RESTAURANT-APP\\\\public\\\\Opsos deck.html\")",
      "WebFetch(domain:inkind.com)",
      "WebFetch(domain:restaurantactivityreport.com)",
      "WebFetch(domain:leads.restaurantactivityreport.com)",
      "Bash(npx puppeteer:*)"
    ],
    "deny": [],
    "ask": []
  }
}
